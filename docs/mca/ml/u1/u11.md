# Introduction to Machine Learning

Machine learning (ML) gained significant serious attention more than 20 years ago when **IBM’s Deep Blue defeated world chess champion Gary Kasparov**. ML is a subfield of computer science and an inevitable product of artificial intelligence (AI) studies.

Today, ML is considered a **mature technology area**. Its applications are widespread, including:

- Recommending products to buyers (e.g., toys to toddlers or books to geeks).
- Predicting future markets (e.g., real estate or stocks).
- Assisting medical practitioners in diagnosis (e.g., finding if a tumor is malignant or benign).
- Optimizing energy consumption (supporting the cause of Green Earth).

Companies like Google are front-runners in ML/AI research, with ambitious projects such as the Google self-driving car and Google Brain.

## 1.1 What is Human Learning?

In cognitive science, **learning is typically referred to as the process of gaining information through observation**. Humans need to learn to carry out various activities, ranging from simple tasks like walking to complex tasks like determining a rocket launch angle.

- **Necessity of Prior Information:** To execute a task properly, prior information related to the task is required.
- **Improvement through Learning:** As a person acquires more information (learns), the efficiency in performing tasks improves. For example, more knowledge reduces mistakes in homework, and experience from past rocket launches helps ensure successful future launches.

## 1.2 Types of Human Learning

The core philosophy of human learning involves **learning from expert guidance and from experience**. Human learning is conventionally categorized into three distinct types:

1.  **Learning under expert guidance.**
2.  **Learning guided by knowledge gained from experts.**
3.  **Learning by self.**

The core philosophy underlying human learning, which machine learning algorithms generally imbibe.

### 1. Learning under expert guidance (Guided Learning)

This type of learning occurs when a person acquires knowledge directly from someone who is an expert in the subject (already gathered knowledge based on their past experience in that field). This process is known as **guided learning**.

**Definition:** Guided learning is the process of gaining information from a person possessing sufficient knowledge due to past experience.

- A student in school learning complex subjects like basic mathematics, science, or grammar from a teacher.
- A new professional learning hands-on application of theoretical knowledge from a mentor who has years of experience.

> **ML Analogy: Supervised Learning**
>
> This type of human learning correlates directly with **Supervised Learning**.
>
> - Supervised learning involves learning from **labelled training data** (the "expert/teacher") which provides known classes or values.
> - The machine is guided by human input (the labels) to assign classes or values to new, unknown data.

### 2. Learning guided by knowledge gained from experts (Indirect Learning)

This form of learning utilizes previously acquired knowledge imparted by an expert at some point in a different form or context is leveraged as learning to inform current decisions in a new context. It involves **no direct learning** for the task currently being performed (task unknown).

1.  **Grouping by Color:** A baby might be able to group objects of the same color together, even though the parents never explicitly taught the grouping task. The baby does this because the parents had previously taught them which color is blue, red, or green, etc., at some other point in time.
2.  **Identifying Word Types:** A grown-up child can successfully select the one "odd word" from a set of words (e.g., identifying a verb among nouns). This ability stems from the foundational knowledge (labeling words as verbs or nouns) taught by an English teacher long ago, in a separate educational context.

> **ML Analogy: Unsupervised Learning**
>
> - Unsupervised learning works with **unlabelled data** and attempts to find natural patterns or groupings (like clustering similar objects by shape) within the data elements.
> - The learning is not guided by labeled inputs but utilizes the knowledge implicit in the data or knowledge previously gained from the concepts themselves.

### 3. Learning by self (Self-Learning)

In this scenario, humans must learn autonomously, often without direct instruction, relying entirely on trial and error.

Learning happens through continuous observation and correction, typically **learning only from mistakes** made in the past. This process leads to the formation of a checklist or set of internal rules regarding what should and should not be done, based solely on individual experience.

- A child learning to ride a bicycle or an adult learning to drive a car; not all aspects of these tasks are taught directly by others.

> **ML Analogy: Reinforcement Learning (RL)**
>
> - In RL, the machine (the agent) learns to act autonomously to achieve given goals.
> - It improves performance by gathering "experience" and receiving a **reward** when a sub-task is accomplished successfully, and no reward (or punishment/penalty) when it is not executed correctly. This reward/punishment mechanism guides the machine to learn by itself.

### Other Core Learning Concepts

- **Induction** (or inductive learning) is the fundamental tool of scientific reasoning that proceeds **from specialization to generalization**. It involves summarizing specific observations into generalized rules. Learning from examples is an inductive process.

- **Deduction** is reasoning **from generalization to specialization**, deriving specific cases from basic principles.

- **Rote learning** is the approach of simply memorizing training examples. Rote learning is also known as memorization-based learning and involves saving all input information as it is and retrieving it when needed, meaning **it does not perform any real learning**.

## 1.3 What is Machine Learning?

Machine learning (ML) is generally defined as the science and engineering of building machines capable of doing useful things without being explicitly programmed to do so.

**Definition of Machine Learning:** The most relevant, concise, and universally accepted definition is provided by **Tom M. Mitchell**:

> “A computer program is said to learn from experience **E** with respect to some class of tasks **T** and performance measure **P**, if its performance at tasks in **T**, as measured by **P**, improves with experience **E**.”

This definition essentially means that a machine is considered to learn if it can:

- Gather **experience (E)** by doing a certain task.
- Improve its **performance (P)** in performing similar tasks in the future.
- Past experience refers to **past data** related to the task, which is input to the machine.

**ML as a Process:** ML can be defined as the process of solving a practical problem by
1) gathering a dataset, and 
2) algorithmically building a **statistical model** based on that dataset.

### 1.3.1 How do machines learn?

The machine learning (ML) process fundamentally attempts to emulate the way humans learn. It is based on developing learning algorithms that generate models from data.

The basic machine learning process can be systematically divided into three basic parts:

1.  **Data Input**
    Past data or information is utilized as the initial foundation for future decision-making. The concept of "experience" is through **past data** related to the task provided as an input to the machine from some source.
    - **Data Quality:** The effectiveness of the learning process depends heavily on the quality of this data input; if the training data is of poor quality, the resultant predictions will be imprecise.

2.  **Abstraction (Model Building)**
    The input data is represented in a summarized & broader way through the underlying algorithm. This process derives a **conceptual map, or a model**, from the input data which serves as a **summarized knowledge representation** of the raw data.
    - Raw data cannot be used in original shape and form, needing this transformation process.
    - Models can take forms such as computational blocks (if/else rules), mathematical equations (representing linear regression), specific data structures (trees/graphs), or logical groupings of similar observations.

3.  **Generalization**
    The abstracted representation (model) is tuned and generalized to form a framework for making decisions on unknown data it has never seen before.
    - This is crucial because the model, trained on a **finite set of data**, must be able to apply conclusions correctly to unknown data sets (test data).
    - Generalization is the ability to work well on new samples (or unseen samples) is the objective of machine learning.
    - **Risk of Overfitting:** If a model is aligned too closely with the training data, capturing specific nuances, noise, or outliers, this can negatively impact its performance on test data, a problem known as **overfitting**.
    - **Heuristic Approach:** Generalization often requires an **approximate or heuristic approach** rather than precise, reason-based decision-making, especially when facing data characteristics previously unknown to the training set.

### 1.3.2 The Well-Posed Learning Problem

Before applying ML, it must be determined whether the problem is the right candidate to be solved using ML techniques. Defining the problem correctly is paramount, as solving the wrong problem, even with powerful algorithms, leads to meaningless results.

A simple framework for stating or defining a **well-posed learning problem** involves answering three questions:

1.  **What is the problem?**
2.  **Why does the problem need to be solved?**
3.  **How to solve the problem?**

## 1.4 Core ML Concepts: Hypothesis and Bias

- **Hypothesis Space:** This is the collection of all possible hypotheses (models) of a specified form. In concept learning, ML is seen as searching within this space for a **hypothesis that is consistent with the training set**. A consistent hypothesis correctly classifies all training examples.

- **Inductive Bias (Bias):** This refers to the **preference mechanism** an algorithm uses to select a specific hypothesis from the version space (the set of hypotheses consistent with the training examples).

- Every effective learning algorithm **must have its own inductive bias**. Without it, the learning outcome would be uncertain because different consistent hypotheses might predict new samples differently.
