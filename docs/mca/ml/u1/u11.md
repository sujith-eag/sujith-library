# Introduction to Machine Learning

Machine learning (ML) gained significant mainstream attention over two decades ago when **IBM’s Deep Blue defeated world chess champion Gary Kasparov**. As a subfield of computer science, ML is an essential component and product of artificial intelligence (AI) studies.

Today, ML is considered a **mature technology area** with widespread applications, including:

- Recommending products to buyers (e.g., books or movies).
    
- Predicting future market trends (e.g., real estate or stocks).
    
- Assisting medical practitioners in diagnosis (e.g., classifying tumors as malignant or benign).
    
- Optimizing energy consumption.
    

Companies like Google are front-runners in ML/AI research, developing ambitious projects such as the Google self-driving car and Google Brain.

## 1.1 What is Human Learning?

In cognitive science, **learning is typically referred to as the process of gaining information through observation**. Humans must learn to perform tasks ranging from simple (like walking) to complex (like calculating a rocket launch angle).

- **Necessity of Prior Information:** Executing a task properly requires prior information related to that task.
    
- **Improvement through Learning:** As a person acquires more information (learns), their efficiency in performing tasks improves. For example, experience from past rocket launches helps ensure the success of future launches.
    
## 1.2 Types of Human Learning (Analogies for ML)

The core philosophy of human learning involves **learning from expert guidance and from experience**. This is conventionally categorized into three types, which provide a strong analogy for the primary types of machine learning.

1.  Learning under expert guidance.
2.  Learning guided by knowledge gained from experts.
3.  Learning by self.

### 1. Guided Learning (Learning Under Expert Guidance)

This learning occurs when a person acquires knowledge directly from an expert who has accumulated experience in a field.

- **Definition:** Guided learning is the process of gaining information from a person possessing sufficient knowledge due to past experience.
    - A student learning mathematics or science from a teacher.
        
    - A new professional learning the practical application of theoretical knowledge from an experienced mentor.
        

> **ML Analogy: Supervised Learning**
> 
> This process correlates directly with **Supervised Learning**.
> 
> - Supervised learning involves learning from **labeled training data** (the "expert" or "teacher"), which provides known answers or values.
>     
> - The machine is guided by this human-provided input to learn how to assign correct classes or values to new, unknown data.
>     

### 2. Indirect Learning (Knowledge-Based Grouping)

This form utilizes previously acquired knowledge (imparted by an expert in a different context) to make decisions in a new context, with **no direct "teacher"** for the new task. **No direct learning** for the task currently being performed (task unknown).

- **Grouping by Color:** A baby can group objects of the same color together. The baby was not explicitly taught the _task of grouping_, but they can perform it by leveraging prior, separate knowledge of _what colors are_ (taught by a parent).
	
- **Identifying Word Types:** A student can identify the "odd word" from a set (e.g., a verb among nouns). This ability stems from foundational knowledge (labeling words as verbs or nouns) taught by a teacher long ago, applied to a new task.
        

> **ML Analogy: Unsupervised Learning**
> 
> - Unsupervised learning works with **unlabeled data** and attempts to find natural patterns or groupings (clusters) within the data.
>     
> - The learning is not guided by labeled answers but utilizes the inherent structure of the data itself.
>     

### 3. Self-Learning (Learning from Experience)

In this scenario, humans learn autonomously, often without direct instruction, by relying on trial and error.

Learning happens through continuous observation and correction, typically **learning from the outcomes (mistakes or successes)** of past actions. This builds an internal set of rules based on individual experience.

- A child learning to ride a bicycle or an adult learning to drive a car.
    

> **ML Analogy: Reinforcement Learning (RL)**
> 
> - In RL, the machine (the **agent**) learns to act autonomously to achieve a goal.
>     
> - It improves performance by gathering "experience" and receiving a **reward** for successful actions or a **penalty** for incorrect ones. This feedback mechanism guides the machine to learn by itself.
>     


## 1.3 What is Machine Learning?

Machine learning (ML) is the science and engineering of building machines capable of performing useful tasks without being explicitly programmed to do so.

The most concise and universally accepted definition is provided by **Tom M. Mitchell**:

> “A computer program is said to learn from experience **E** with respect to some class of tasks **T** and performance measure **P**, if its performance at tasks in **T**, as measured by **P**, improves with experience **E**.”

This means a machine learns if it can:

- Gather **experience (E)** from past data.
    
- Improve its **performance (P)** at a specific **task (T)**.
    
___

- Gather **experience (E)** by doing a certain task.
- Improve its **performance (P)** in performing similar tasks in the future.
- Past experience refers to **past data** related to the task, which is input to the machine.

___

ML can also be defined as the process of solving a practical problem by:

1. Gathering a dataset.
    
2. Algorithmically building a **statistical model** based on that dataset.
    

### 1.3.1 The Well-Posed Learning Problem

Before applying ML, it is essential to define the problem correctly. A framework for a **well-posed learning problem** involves answering three questions:

1. **What is the problem?** (The task **T**)
    
2. **Why does the problem need to be solved?** (The performance measure **P**)
    
3. **How to solve the problem?** (The experience **E** to learn from)
    

### 1.3.2 The Machine Learning Process

The ML process emulates human learning by developing algorithms that generate models from data. This process can be divided into three basic parts:

1. **Data Input (Experience) :** Past data or information (experience) related to the provided task is used as the foundation for decision-making. The effectiveness of the learning process depends heavily on the quality of the data; poor-quality training data will lead to imprecise models.
    
2. **Abstraction (Model Building) :** The input data is represented in a summarized, broader way. The algorithm derives a conceptual map, or **model**, which serves as a **summarized knowledge representation** of the raw data.
	
    - **Models** can take forms such as computational blocks (if/else rules), mathematical equations (representing linear regression), specific data structures (trees/graphs), or logical groupings of similar observations.
	
    - This process is a form of **Inductive Learning**: proceeding from specific observations (the data) to generalized rules (the model).
        
    - This is the opposite of **Deductive Learning**, which reasons from general, known principles to derive specific conclusions.
        
3. **Generalization (Application) :** The model (abstracted representation) is applied to new, unknown data. Generalization is the ability of a model to perform well on unseen samples (test data), which is the primary objective of machine learning.
    
    - **Risk of Overfitting:** If a model is aligned too closely with its training data (capturing noise or outliers), its performance on new data will be poor. This is called **overfitting**.
        
    - The opposite of generalization is **rote learning** (memorization), where a model can only "predict" data it has already seen.
        
    - Because the model is trained on a finite set of data, generalization often requires an **approximate or heuristic approach** rather than perfect, reason-based decision-making especially when facing data characteristics previously unknown to the training set.
        

## 1.4 Core ML Concepts: Hypothesis and Bias

- **Hypothesis Space:** This is the collection of all possible models (hypotheses) that an algorithm can create. In concept learning, ML is viewed as a search within this space for a **hypothesis that is consistent with the training set**. A consistent hypothesis correctly classifies all training examples.
    
- **Inductive Bias (Bias):** This refers to the **preference mechanism** or assumptions an algorithm uses to choose one specific hypothesis from all the possibilities that fit the training data.
    
- Every effective learning algorithm **must have its own inductive bias**. Without it, the algorithm would be unable to make a definitive choice between different hypotheses that all fit the data, leading to uncertain predictions on new samples.

### Other Core Learning Concepts

- **Induction** (or inductive learning) is the fundamental tool of scientific reasoning that proceeds **from specialization to generalization**. It involves summarizing specific observations into generalized rules. Learning from examples is an inductive process.

- **Deduction** is reasoning **from generalization to specialization**, deriving specific cases from basic principles.

- **Rote learning** is the approach of simply memorizing training examples. Rote learning is also known as memorization-based learning and involves saving all input information as it is and retrieving it when needed, meaning **it does not perform any real learning**.
